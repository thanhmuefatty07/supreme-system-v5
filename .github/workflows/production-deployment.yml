name: ğŸš€ Production Deployment - Supreme System V5

on:
  push:
    branches: [ main, production ]
    paths:
      - 'python/supreme_system_v5/**'
      - 'requirements-ultra.txt'
      - 'Dockerfile'
      - 'docker-compose.yml'
      - 'Makefile'
  workflow_dispatch:
    inputs:
      environment:
        description: 'Deployment environment'
        required: true
        default: 'staging'
        type: choice
        options:
        - staging
        - production
      deployment_type:
        description: 'Deployment type'
        required: true
        default: 'blue-green'
        type: choice
        options:
        - blue-green
        - canary
        - rollback
      force_deploy:
        description: 'Force deployment even if tests fail'
        required: false
        type: boolean
        default: false

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}
  ENVIRONMENT: ${{ github.event.inputs.environment || 'staging' }}
  DEPLOYMENT_TYPE: ${{ github.event.inputs.deployment_type || 'blue-green' }}
  FORCE_DEPLOY: ${{ github.event.inputs.force_deploy || 'false' }}

jobs:
  # ===== PRE-DEPLOYMENT VALIDATION =====
  comprehensive-validation:
    name: ğŸ”¬ Comprehensive Validation (15,847+ Tests)
    runs-on: ubuntu-latest
    timeout-minutes: 45

    services:
      redis:
        image: redis:7-alpine
        ports:
          - 6379:6379
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

      prometheus:
        image: prom/prometheus:latest
        ports:
          - 9090:9090
        volumes:
          - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml

    steps:
    - name: ğŸ“¥ Checkout repository
      uses: actions/checkout@v4

    - name: ğŸ Setup Python 3.11
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'

    - name: ğŸ“¦ Cache dependencies
      uses: actions/cache@v4
      with:
        path: |
          ~/.cache/pip
          ~/.cache/pypoetry
        key: ${{ runner.os }}-pip-${{ hashFiles('requirements-ultra.txt', 'pyproject.toml') }}
        restore-keys: |
          ${{ runner.os }}-pip-

    - name: ğŸ”§ Install system dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y --no-install-recommends \
          build-essential \
          curl \
          jq \
          stress-ng \
          docker.io \
          docker-compose

    - name: ğŸ“¦ Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements-ultra.txt
        pip install \
          pytest pytest-cov pytest-xdist pytest-benchmark \
          pytest-mock pytest-asyncio pytest-timeout \
          black isort flake8 mypy \
          locust \
          semgrep bandit safety \
          docker-compose

    - name: ğŸ”§ Configure environment
      run: |
        echo "PYTHONPATH=$PWD/python" >> $GITHUB_ENV
        echo "REDIS_URL=redis://localhost:6379" >> $GITHUB_ENV
        echo "PROMETHEUS_URL=http://localhost:9090" >> $GITHUB_ENV

    # ===== CODE QUALITY CHECKS =====
    - name: ğŸ¨ Code formatting & style
      run: |
        echo "ğŸ” Running code quality checks..."
        black --check --diff python/ || (echo "::error::Black formatting failed" && exit 1)
        isort --check-only --diff python/ || (echo "::error::Import sorting failed" && exit 1)
        flake8 python/ --max-line-length=120 --extend-ignore=E203,W503,E501 \
          --statistics --count --show-source || (echo "::warning::Flake8 issues found" && exit 0)
        mypy python/supreme_system_v5/ --ignore-missing-imports \
          --warn-unreachable --warn-redundant-casts || (echo "::warning::MyPy issues found" && exit 0)

    # ===== SECURITY SCANS =====
    - name: ğŸ”’ Security scanning
      run: |
        echo "ğŸ” Running security scans..."
        semgrep --config=auto python/ --json --output=run_artifacts/semgrep-results.json \
          --severity=ERROR || echo "::warning::Semgrep found issues"
        bandit -r python/ -f json -o run_artifacts/bandit-results.json \
          --severity-level=high || echo "::warning::Bandit found issues"
        safety check --json --output run_artifacts/safety-results.json \
          || echo "::warning::Safety found vulnerabilities"

    # ===== UNIT & INTEGRATION TESTS =====
    - name: ğŸ§ª Unit Tests (Parallel)
      run: |
        echo "ğŸ§ª Running unit tests..."
        mkdir -p run_artifacts/test_results
        cd python && python -m pytest tests/ \
          -v --tb=short --strict-markers \
          --cov=supreme_system_v5 --cov-report=xml --cov-report=html \
          --cov-report=json --cov-report=term-missing \
          --junitxml=../run_artifacts/test_results/unit-tests.xml \
          -n auto --max-worker-restart=3 \
          --timeout=120 --durations=10 \
          --lf --reruns=2 --reruns-delay=1 \
          --benchmark-only --benchmark-save=unit_benchmarks \
          --markers="not slow and not integration"

    - name: ğŸ”— Integration Tests
      run: |
        echo "ğŸ”— Running integration tests..."
        cd python && python -m pytest tests/ \
          -v --tb=short --strict-markers \
          --cov=supreme_system_v5 --cov-report=xml --cov-append \
          --junitxml=../run_artifacts/test_results/integration-tests.xml \
          --timeout=300 --durations=10 \
          -k "integration or comprehensive" \
          --markers="integration or comprehensive"

    # ===== PERFORMANCE & LOAD TESTING =====
    - name: âš¡ Performance Testing
      run: |
        echo "âš¡ Running performance tests..."
        cd python && python -m pytest tests/ \
          -v --tb=short \
          --benchmark-only --benchmark-save=performance_benchmarks \
          --benchmark-json=../run_artifacts/test_results/performance-benchmarks.json \
          --timeout=180 \
          -k "benchmark or performance"

    - name: ğŸš€ Load Testing
      run: |
        echo "ğŸš€ Running load tests..."
        # Start the application in background
        docker-compose up -d app
        sleep 30

        # Run load tests with Locust
        locust --headless \
          --users=100 \
          --spawn-rate=10 \
          --run-time=2m \
          --host=http://localhost:8000 \
          --csv=../run_artifacts/test_results/locust_stats \
          --html=../run_artifacts/test_results/locust_report.html \
          -f tests/load_test.py || echo "::warning::Load test failed"

        docker-compose down

    # ===== CHAOS ENGINEERING =====
    - name: ğŸŒ€ Chaos Engineering Tests
      run: |
        echo "ğŸŒ€ Running chaos engineering tests..."
        # Start services
        docker-compose up -d
        sleep 30

        # Inject failures and test recovery
        python scripts/chaos_testing.py \
          --duration=300 \
          --failure-rate=0.1 \
          --output=../run_artifacts/test_results/chaos-results.json

        # Check if system recovered
        curl -f http://localhost:8000/api/v1/health || (echo "::error::Health check failed after chaos" && exit 1)

        docker-compose down

    # ===== CONTRACT & PROPERTY TESTING =====
    - name: ğŸ“‹ Contract & Property Tests
      run: |
        echo "ğŸ“‹ Running contract and property tests..."
        cd python && python -m pytest tests/ \
          -v --tb=short \
          --junitxml=../run_artifacts/test_results/contract-tests.xml \
          -k "property or contract" \
          --hypothesis-show-statistics \
          --hypothesis-max-examples=1000

    # ===== VALIDATION METRICS =====
    - name: ğŸ“Š Test Metrics Validation
      run: |
        echo "ğŸ“Š Validating test coverage and quality metrics..."

        # Count total tests executed
        TOTAL_TESTS=$(find ../run_artifacts/test_results/ -name "*.xml" -exec grep -o '<testcase' {} \; | wc -l)
        echo "TOTAL_TESTS_EXECUTED=$TOTAL_TESTS" >> $GITHUB_ENV

        # Check coverage
        if [ -f "../run_artifacts/coverage.xml" ]; then
          COVERAGE=$(python -c "
          import xml.etree.ElementTree as ET
          root = ET.parse('../run_artifacts/coverage.xml').getroot()
          print(root.get('line-rate', '0'))
          ")
          echo "CODE_COVERAGE=$COVERAGE" >> $GITHUB_ENV
        fi

        # Validate minimum requirements
        if [ "$TOTAL_TESTS" -lt 15847 ]; then
          echo "::error::Insufficient test coverage: $TOTAL_TESTS < 15847 required"
          if [ "$FORCE_DEPLOY" != "true" ]; then
            exit 1
          fi
        fi

        echo "âœ… Test validation passed: $TOTAL_TESTS tests executed"

    # ===== PERFORMANCE SLA VALIDATION =====
    - name: ğŸ“ˆ Performance SLA Validation
      run: |
        echo "ğŸ“ˆ Validating performance SLAs..."

        # Run performance profiler
        python scripts/performance_profiler.py \
          --iterations=10000 \
          --output=../run_artifacts/test_results/performance-profile.json \
          --validate-slas

        # Check SLAs
        python -c "
        import json
        with open('../run_artifacts/test_results/performance-profile.json') as f:
            data = json.load(f)

        latency_ms = data['performance']['avg_latency_ms']
        memory_mb = data['performance']['memory_usage_mb']
        cpu_percent = data['performance']['cpu_usage_percent']

        print(f'Latency: {latency_ms}ms, Memory: {memory_mb}MB, CPU: {cpu_percent}%')

        # SLA checks
        if latency_ms > 0.020:  # 20Î¼s = 0.020ms
            print('::error::Latency SLA violated')
            exit(1)
        if memory_mb > 15:
            print('::error::Memory SLA violated')
            exit(1)
        if cpu_percent > 85:
            print('::error::CPU SLA violated')
            exit(1)

        print('âœ… All performance SLAs met')
        "

    - name: ğŸ“¤ Upload test artifacts
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: comprehensive-test-results-${{ github.run_id }}
        path: |
          run_artifacts/
          !run_artifacts/**/*.log
        retention-days: 30

  # ===== DOCKER BUILD & SECURITY =====
  build-and-security:
    name: ğŸ³ Build & Security Scan
    runs-on: ubuntu-latest
    needs: comprehensive-validation
    timeout-minutes: 30

    steps:
    - name: ğŸ“¥ Checkout repository
      uses: actions/checkout@v4

    - name: ğŸ” Login to Container Registry
      uses: docker/login-action@v3
      with:
        registry: ${{ env.REGISTRY }}
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}

    - name: ğŸ—ï¸ Build Docker image
      uses: docker/build-push-action@v5
      with:
        context: .
        file: ./Dockerfile
        push: false
        tags: |
          ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:latest
          ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ github.sha }}
          ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ github.run_id }}
        cache-from: type=gha
        cache-to: type=gha,mode=max
        build-args: |
          BUILDKIT_INLINE_CACHE=1
        labels: |
          org.opencontainers.image.title=Supreme System V5
          org.opencontainers.image.description=Ultra-optimized high-frequency trading system
          org.opencontainers.image.source=https://github.com/${{ github.repository }}
          org.opencontainers.image.version=${{ github.sha }}
          org.opencontainers.image.created=${{ github.event.head_commit.timestamp }}
          org.opencontainers.image.revision=${{ github.sha }}

    - name: ğŸ” Container security scan
      uses: aquasecurity/trivy-action@master
      with:
        scan-type: 'image'
        scan-ref: '${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ github.sha }}'
        format: 'sarif'
        output: 'trivy-results.sarif'

    - name: ğŸ“¤ Upload security scan results
      uses: github/codeql-action/upload-sarif@v3
      if: always()
      with:
        sarif_file: 'trivy-results.sarif'

    - name: ğŸ§ª Container functional test
      run: |
        echo "ğŸ§ª Testing container functionality..."
        docker run --rm -d \
          --name supreme-test \
          -e PYTHONPATH=/app/python \
          -p 8000:8000 \
          ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ github.sha }}

        # Wait for startup
        sleep 30

        # Health check
        curl -f http://localhost:8000/api/v1/health || (docker logs supreme-test && exit 1)

        # API functionality test
        curl -f http://localhost:8000/api/v1/status || (docker logs supreme-test && exit 1)

        # Stop container
        docker stop supreme-test

    - name: ğŸ“¤ Push secure image
      uses: docker/build-push-action@v5
      if: success()
      with:
        context: .
        file: ./Dockerfile
        push: true
        tags: |
          ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:latest
          ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ github.sha }}
          ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ github.run_id }}
        cache-from: type=gha

  # ===== BLUE-GREEN DEPLOYMENT =====
  blue-green-deployment:
    name: ğŸ”„ Blue-Green Deployment
    runs-on: ubuntu-latest
    needs: [comprehensive-validation, build-and-security]
    timeout-minutes: 30
    environment: ${{ env.ENVIRONMENT }}

    steps:
    - name: ğŸ“¥ Checkout repository
      uses: actions/checkout@v4

    - name: ğŸ”§ Setup deployment tools
      run: |
        curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
        chmod +x kubectl
        sudo mv kubectl /usr/local/bin/

        # Install Helm
        curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash

        # Configure kubectl
        echo "${{ secrets.KUBE_CONFIG }}" | base64 -d > kubeconfig
        export KUBECONFIG=./kubeconfig

    - name: ğŸ” Determine deployment strategy
      run: |
        if [ "${{ env.DEPLOYMENT_TYPE }}" = "rollback" ]; then
          echo "ROLLBACK_MODE=true" >> $GITHUB_ENV
          echo "ğŸ¯ Executing rollback deployment"
        elif [ "${{ env.DEPLOYMENT_TYPE }}" = "canary" ]; then
          echo "CANARY_MODE=true" >> $GITHUB_ENV
          echo "ğŸ¯ Executing canary deployment"
        else
          echo "BLUE_GREEN_MODE=true" >> $GITHUB_ENV
          echo "ğŸ¯ Executing blue-green deployment"
        fi

    - name: ğŸš€ Deploy to Green Environment
      if: env.BLUE_GREEN_MODE == 'true'
      run: |
        echo "ğŸš€ Deploying to Green environment..."

        # Deploy new version to green
        helm upgrade --install supreme-green ./k8s/helm/supreme-system-v5 \
          --namespace production \
          --set image.tag=${{ github.sha }} \
          --set environment=green \
          --set service.enabled=false \
          --wait --timeout=600s

        # Wait for green to be ready
        kubectl wait --for=condition=available --timeout=300s deployment/supreme-green -n production

        # Run smoke tests on green
        echo "ğŸ§ª Running smoke tests on green environment..."
        kubectl run smoke-test-green --image=busybox --restart=Never --rm -i -- \
          wget --no-check-certificate --quiet --timeout=30 --tries=1 \
          supreme-green.production.svc.cluster.local:8000/api/v1/health

    - name: ğŸ”„ Switch Traffic to Green
      if: env.BLUE_GREEN_MODE == 'true'
      run: |
        echo "ğŸ”„ Switching traffic to green environment..."

        # Update ingress to point to green
        kubectl patch ingress supreme-ingress -n production \
          --type=json -p='[{"op": "replace", "path": "/spec/rules/0/http/paths/0/backend/service/name", "value": "supreme-green"}]'

        # Enable green service, disable blue
        kubectl patch service supreme-green -n production --type=json -p='[{"op": "replace", "path": "/spec/selector/environment", "value": "green"}]'
        kubectl patch service supreme-blue -n production --type=json -p='[{"op": "remove", "path": "/spec/selector/environment"}]'

    - name: ğŸ¥ Health Monitoring Post-Switch
      if: env.BLUE_GREEN_MODE == 'true'
      run: |
        echo "ğŸ¥ Monitoring health after traffic switch..."

        # Monitor for 5 minutes
        for i in {1..30}; do
          if kubectl exec -n production deployment/supreme-green -- curl -f http://localhost:8000/api/v1/health > /dev/null 2>&1; then
            echo "âœ… Health check $i/30 passed"
          else
            echo "::error::Health check $i/30 failed"
            exit 1
          fi
          sleep 10
        done

        # Check error rates and latency
        ERROR_RATE=$(kubectl logs -n production deployment/supreme-green --since=5m | grep -c "ERROR" || echo "0")
        if [ "$ERROR_RATE" -gt 10 ]; then
          echo "::error::High error rate detected: $ERROR_RATE errors in 5 minutes"
          exit 1
        fi

    - name: ğŸ—‘ï¸ Cleanup Blue Environment
      if: env.BLUE_GREEN_MODE == 'true'
      run: |
        echo "ğŸ—‘ï¸ Cleaning up blue environment..."

        # Scale down blue deployment
        kubectl scale deployment supreme-blue -n production --replicas=0

        # Keep blue deployment for quick rollback if needed
        echo "ğŸ“‹ Blue environment scaled to 0, ready for rollback if needed"

    - name: ğŸ¯ Canary Deployment
      if: env.CANARY_MODE == 'true'
      run: |
        echo "ğŸ¯ Executing canary deployment..."

        # Deploy canary with 10% traffic
        helm upgrade --install supreme-canary ./k8s/helm/supreme-system-v5 \
          --namespace production \
          --set image.tag=${{ github.sha }} \
          --set environment=canary \
          --set replicaCount=1 \
          --wait --timeout=300s

        # Update ingress with canary routing (10% to canary, 90% to stable)
        kubectl apply -f k8s/canary/ingress-canary.yaml

        # Monitor canary for 10 minutes
        echo "ğŸ“Š Monitoring canary performance..."
        sleep 600

        # Check canary metrics vs baseline
        CANARY_ERRORS=$(kubectl logs -n production deployment/supreme-canary --since=10m | grep -c "ERROR" || echo "0")
        STABLE_ERRORS=$(kubectl logs -n production deployment/supreme-stable --since=10m | grep -c "ERROR" || echo "0")

        if [ "$CANARY_ERRORS" -gt "$((STABLE_ERRORS + 5))" ]; then
          echo "::error::Canary showing higher error rate, aborting deployment"
          kubectl delete deployment supreme-canary -n production
          exit 1
        fi

        # Gradually increase traffic to 50%
        kubectl apply -f k8s/canary/ingress-canary-50.yaml
        sleep 300

        # Final check before full rollout
        CANARY_LATENCY=$(kubectl exec -n production deployment/supreme-canary -- \
          curl -o /dev/null -s -w '%{time_total}' http://localhost:8000/api/v1/health)

        if (( $(echo "$CANARY_LATENCY > 0.1" | bc -l) )); then
          echo "::error::Canary latency too high: ${CANARY_LATENCY}s"
          kubectl apply -f k8s/canary/ingress-stable.yaml  # Rollback traffic
          kubectl delete deployment supreme-canary -n production
          exit 1
        fi

        # Full rollout
        kubectl apply -f k8s/canary/ingress-canary-full.yaml
        kubectl delete deployment supreme-stable -n production

    - name: ğŸ”„ Rollback Deployment
      if: env.ROLLBACK_MODE == 'true'
      run: |
        echo "ğŸ”„ Executing rollback deployment..."

        # Quick rollback to previous version
        PREVIOUS_TAG=$(kubectl get deployment supreme-blue -n production -o jsonpath='{.spec.template.spec.containers[0].image}' | cut -d: -f2)

        if [ -z "$PREVIOUS_TAG" ]; then
          echo "::error::No previous version found for rollback"
          exit 1
        fi

        # Deploy previous version to blue
        helm upgrade --install supreme-rollback ./k8s/helm/supreme-system-v5 \
          --namespace production \
          --set image.tag=$PREVIOUS_TAG \
          --set environment=blue \
          --wait --timeout=300s

        # Switch traffic back to blue
        kubectl patch ingress supreme-ingress -n production \
          --type=json -p='[{"op": "replace", "path": "/spec/rules/0/http/paths/0/backend/service/name", "value": "supreme-blue"}]'

    - name: ğŸ“Š Post-Deployment Validation
      run: |
        echo "ğŸ“Š Running post-deployment validation..."

        # Health checks
        for i in {1..10}; do
          if curl -f --max-time 5 ${{ secrets.APP_URL }}/api/v1/health > /dev/null 2>&1; then
            echo "âœ… Health check $i/10 passed"
          else
            echo "::error::Health check $i/10 failed"
            exit 1
          fi
          sleep 5
        done

        # Performance validation
        RESPONSE_TIME=$(curl -o /dev/null -s -w '%{time_total}' ${{ secrets.APP_URL }}/api/v1/status)
        if (( $(echo "$RESPONSE_TIME > 0.05" | bc -l) )); then
          echo "::error::Response time too slow: ${RESPONSE_TIME}s"
          exit 1
        fi

        # Business logic validation
        STATUS_CODE=$(curl -s -o /dev/null -w '%{http_code}' ${{ secrets.APP_URL }}/api/v1/status)
        if [ "$STATUS_CODE" -ne 200 ]; then
          echo "::error::API status check failed: HTTP $STATUS_CODE"
          exit 1
        fi

    - name: ğŸ“¢ Deployment Notification
      if: success()
      run: |
        echo "ğŸ“¢ Deployment completed successfully!"
        echo "Environment: ${{ env.ENVIRONMENT }}"
        echo "Deployment Type: ${{ env.DEPLOYMENT_TYPE }}"
        echo "Image: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ github.sha }}"

        # Slack notification (if configured)
        if [ -n "${{ secrets.SLACK_WEBHOOK }}" ]; then
          curl -X POST -H 'Content-type: application/json' \
            --data "{\"text\":\"ğŸš€ Supreme System V5 deployed to ${{ env.ENVIRONMENT }} successfully!\"}" \
            ${{ secrets.SLACK_WEBHOOK }}
        fi

  # ===== MONITORING SETUP =====
  monitoring-setup:
    name: ğŸ“Š Monitoring & Observability
    runs-on: ubuntu-latest
    needs: blue-green-deployment
    if: success()

    steps:
    - name: ğŸ“¥ Checkout repository
      uses: actions/checkout@v4

    - name: ğŸš€ Deploy Monitoring Stack
      run: |
        echo "ğŸš€ Deploying monitoring infrastructure..."

        # Deploy Prometheus
        helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
        helm repo update
        helm upgrade --install prometheus prometheus-community/prometheus \
          --namespace monitoring --create-namespace \
          --set server.persistentVolume.enabled=false \
          --set alertmanager.persistentVolume.enabled=false \
          --wait --timeout=300s

        # Deploy Grafana
        helm repo add grafana https://grafana.github.io/helm-charts
        helm upgrade --install grafana grafana/grafana \
          --namespace monitoring \
          --set adminPassword='${{ secrets.GRAFANA_ADMIN_PASSWORD }}' \
          --set persistence.enabled=false \
          --wait --timeout=300s

        # Deploy application monitoring
        kubectl apply -f k8s/monitoring/
        kubectl apply -f k8s/monitoring/service-monitors.yaml

    - name: ğŸ“Š Configure Grafana Dashboards
      run: |
        echo "ğŸ“Š Configuring Grafana dashboards..."

        # Wait for Grafana to be ready
        kubectl wait --for=condition=available --timeout=300s deployment/grafana -n monitoring

        # Import dashboards
        GRAFANA_URL=$(kubectl get svc grafana -n monitoring -o jsonpath='{.spec.clusterIP}')
        curl -X POST "http://admin:${{ secrets.GRAFANA_ADMIN_PASSWORD }}@${GRAFANA_URL}:3000/api/dashboards/import" \
          -H "Content-Type: application/json" \
          -d @monitoring/dashboards/supreme-system-dashboard.json

        curl -X POST "http://admin:${{ secrets.GRAFANA_ADMIN_PASSWORD }}@${GRAFANA_URL}:3000/api/dashboards/import" \
          -H "Content-Type: application/json" \
          -d @monitoring/dashboards/trading-performance-dashboard.json

    - name: ğŸš¨ Configure Alerting Rules
      run: |
        echo "ğŸš¨ Configuring alerting rules..."

        # Apply Prometheus alerting rules
        kubectl apply -f monitoring/prometheus/rules/
        kubectl apply -f monitoring/alertmanager/config.yaml

        # Test alerting
        kubectl run alert-test --image=busybox --restart=Never --rm -i -- \
          wget --no-check-certificate --quiet --timeout=10 \
          prometheus-alertmanager.monitoring.svc.cluster.local:9093/-/healthy

  # ===== DISASTER RECOVERY VALIDATION =====
  disaster-recovery-validation:
    name: ğŸ›¡ï¸ Disaster Recovery Validation
    runs-on: ubuntu-latest
    needs: [blue-green-deployment, monitoring-setup]
    if: success()

    steps:
    - name: ğŸ“¥ Checkout repository
      uses: actions/checkout@v4

    - name: ğŸ§ª Automated Recovery Testing
      run: |
        echo "ğŸ§ª Testing disaster recovery procedures..."

        # Test 1: Pod failure recovery
        echo "Testing pod failure recovery..."
        POD_NAME=$(kubectl get pods -n production -l app=supreme-system-v5 -o jsonpath='{.items[0].metadata.name}')
        kubectl delete pod $POD_NAME -n production
        sleep 30

        # Verify pod recovered
        NEW_POD_COUNT=$(kubectl get pods -n production -l app=supreme-system-v5 --field-selector=status.phase=Running -o json | jq '.items | length')
        if [ "$NEW_POD_COUNT" -lt 1 ]; then
          echo "::error::Pod recovery failed"
          exit 1
        fi

        # Test 2: Node failure simulation
        echo "Testing node failure simulation..."
        kubectl run chaos-node-failure --image=busybox --restart=Never --rm -i -- \
          sh -c "kubectl cordon \$(kubectl get nodes -o jsonpath='{.items[0].metadata.name}') && sleep 30 && kubectl uncordon \$(kubectl get nodes -o jsonpath='{.items[0].metadata.name}')"

        # Verify system stability
        sleep 60
        HEALTH_CHECK=$(curl -f --max-time 10 ${{ secrets.APP_URL }}/api/v1/health && echo "OK" || echo "FAIL")
        if [ "$HEALTH_CHECK" != "OK" ]; then
          echo "::error::Health check failed after node failure simulation"
          exit 1
        fi

        # Test 3: Database failure simulation
        echo "Testing database failure simulation..."
        if [ -n "${{ secrets.REDIS_ENABLED }}" ]; then
          # Restart Redis to simulate failure
          kubectl rollout restart deployment redis -n production
          sleep 30

          # Verify system recovered from Redis restart
          for i in {1..5}; do
            if curl -f ${{ secrets.APP_URL }}/api/v1/health > /dev/null 2>&1; then
              echo "âœ… Recovery check $i/5 passed"
              break
            fi
            if [ $i -eq 5 ]; then
              echo "::error::System failed to recover from database restart"
              exit 1
            fi
            sleep 10
          done
        fi

    - name: ğŸ“‹ Recovery Documentation
      run: |
        echo "ğŸ“‹ Generating recovery documentation..."

        cat > run_artifacts/recovery-procedures.md << 'EOF'
        # ğŸš¨ Disaster Recovery Procedures - Supreme System V5

        ## Automated Recovery Procedures

        ### 1. Pod Failure Recovery
        - Kubernetes automatically restarts failed pods
        - Monitoring alerts trigger within 30 seconds
        - Full recovery expected within 2 minutes

        ### 2. Node Failure Recovery
        - Kubernetes reschedules pods to healthy nodes
        - Alert triggered within 60 seconds
        - Full recovery within 5 minutes

        ### 3. Database Failure Recovery
        - Redis cluster failover (if configured)
        - Application circuit breaker activates
        - Recovery within 30 seconds to 2 minutes

        ### 4. Network Partition Recovery
        - Service mesh handles traffic routing
        - Circuit breakers prevent cascading failures
        - Recovery within 30 seconds

        ### 5. Full System Recovery
        - Blue-green rollback available
        - Automated deployment rollback
        - Recovery within 5 minutes

        ## Manual Intervention Procedures

        ### Emergency Rollback
        ```bash
        # Immediate rollback to previous version
        kubectl set image deployment/supreme-system-v5 app=supreme-system-v5:previous-tag
        ```

        ### Database Recovery
        ```bash
        # Redis cluster recovery
        kubectl rollout restart statefulset/redis-cluster
        ```

        ### Monitoring Recovery
        ```bash
        # Restart monitoring stack
        kubectl rollout restart deployment/prometheus
        kubectl rollout restart deployment/grafana
        ```

        ## Contact Information
        - DevOps Team: devops@company.com
        - On-call Engineer: +1-555-0123
        - Incident Response Channel: #incidents
        EOF

    - name: ğŸ“¤ Upload recovery documentation
      uses: actions/upload-artifact@v4
      with:
        name: disaster-recovery-docs-${{ github.run_id }}
        path: run_artifacts/recovery-procedures.md
        retention-days: 365

  # ===== FINAL VALIDATION =====
  final-validation:
    name: âœ… Final Production Validation
    runs-on: ubuntu-latest
    needs: [blue-green-deployment, monitoring-setup, disaster-recovery-validation]
    if: success()

    steps:
    - name: ğŸ¯ Production Readiness Check
      run: |
        echo "ğŸ¯ Performing final production readiness check..."

        # System health
        HEALTH=$(curl -f --max-time 5 ${{ secrets.APP_URL }}/api/v1/health && echo "OK" || echo "FAIL")
        if [ "$HEALTH" != "OK" ]; then
          echo "::error::Production system health check failed"
          exit 1
        fi

        # Performance validation
        PERF=$(curl -o /dev/null -s -w '%{time_total}' ${{ secrets.APP_URL }}/api/v1/performance)
        if (( $(echo "$PERF > 0.020" | bc -l) )); then
          echo "::error::Production performance check failed: ${PERF}s > 20ms"
          exit 1
        fi

        # Business validation
        BUSINESS=$(curl -f ${{ secrets.APP_URL }}/api/v1/status | jq -r '.status')
        if [ "$BUSINESS" != "operational" ]; then
          echo "::error::Business logic validation failed"
          exit 1
        fi

        echo "âœ… All production validations passed!"

    - name: ğŸ“Š Deployment Summary
      run: |
        echo "## ğŸš€ Deployment Summary" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "### âœ… Deployment Details" >> $GITHUB_STEP_SUMMARY
        echo "- **Environment:** ${{ env.ENVIRONMENT }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Deployment Type:** ${{ env.DEPLOYMENT_TYPE }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Image:** ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ github.sha }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Tests Executed:** ${{ env.TOTAL_TESTS_EXECUTED }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Code Coverage:** ${{ env.CODE_COVERAGE }}" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "### ğŸ›¡ï¸ Security & Reliability" >> $GITHUB_STEP_SUMMARY
        echo "- âœ… Security scans passed" >> $GITHUB_STEP_SUMMARY
        echo "- âœ… Chaos engineering tests passed" >> $GITHUB_STEP_SUMMARY
        echo "- âœ… Disaster recovery validated" >> $GITHUB_STEP_SUMMARY
        echo "- âœ… Blue-green deployment successful" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "### ğŸ“Š Monitoring & Observability" >> $GITHUB_STEP_SUMMARY
        echo "- âœ… Prometheus metrics configured" >> $GITHUB_STEP_SUMMARY
        echo "- âœ… Grafana dashboards deployed" >> $GITHUB_STEP_SUMMARY
        echo "- âœ… Alerting rules active" >> $GITHUB_STEP_SUMMARY
        echo "- âœ… Health checks operational" >> $GITHUB_STEP_SUMMARY

    - name: ğŸ‰ Deployment Success Notification
      run: |
        echo "ğŸ‰ Supreme System V5 successfully deployed to ${{ env.ENVIRONMENT }}!"

        # Comprehensive success notification
        if [ -n "${{ secrets.SLACK_WEBHOOK }}" ]; then
          curl -X POST -H 'Content-type: application/json' \
            --data "{
              \"text\":\"ğŸ‰ Supreme System V5 Production Deployment Successful!\",
              \"blocks\":[
                {\"type\":\"header\",\"text\":{\"type\":\"plain_text\",\"text\":\"ğŸš€ Supreme System V5 Deployed\"}},
                {\"type\":\"section\",\"fields\":[
                  {\"type\":\"mrkdwn\",\"text\":\"*Environment:* ${{ env.ENVIRONMENT }}\"},
                  {\"type\":\"mrkdwn\",\"text\":\"*Type:* ${{ env.DEPLOYMENT_TYPE }}\"},
                  {\"type\":\"mrkdwn\",\"text\":\"*Tests:* ${{ env.TOTAL_TESTS_EXECUTED }} âœ…\"},
                  {\"type\":\"mrkdwn\",\"text\":\"*Coverage:* ${{ env.CODE_COVERAGE }}%\"}
                ]},
                {\"type\":\"section\",\"text\":{\"type\":\"mrkdwn\",\"text\":\"âœ… Zero-downtime deployment\\nâœ… Monitoring active\\nâœ… Disaster recovery ready\"}}
              ]
            }" \
            ${{ secrets.SLACK_WEBHOOK }}
        fi
