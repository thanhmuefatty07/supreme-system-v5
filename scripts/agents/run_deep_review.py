#!/usr/bin/env python3
"""
ü§ñ Agentic Deep Review System - Automated Code Intelligence
Generates comprehensive analysis packages for AI agents (Gemini, GPT-4, Claude)

Usage:
    python scripts/agents/run_deep_review.py --module strategies
    python scripts/agents/run_deep_review.py --module data_fabric --agent gemini
    python scripts/agents/run_deep_review.py --full-system --output research/
"""

import argparse
import ast
import json
import os
import sys
import time
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any, Optional, Set
import subprocess
import hashlib

# Add project paths
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root / "python"))

print("ü§ñ Agentic Deep Review System")
print("=" * 35)

class CodeIntelligenceAnalyzer:
    """Deep code analysis system for AI agent coordination"""
    
    def __init__(self, output_dir: str = "run_artifacts/agents"):
        self.project_root = project_root
        self.python_root = self.project_root / "python" / "supreme_system_v5"
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        self.analysis_results = {
            'timestamp': datetime.utcnow().isoformat(),
            'project_stats': {},
            'module_analysis': {},
            'complexity_metrics': {},
            'agent_recommendations': {},
            'research_opportunities': []
        }
        
    def analyze_module(self, module_path: str) -> Dict[str, Any]:
        """Perform deep analysis of a specific module"""
        print(f"üîç Analyzing module: {module_path}")
        
        full_path = self.python_root / module_path
        
        if not full_path.exists():
            return {'error': f'Module not found: {module_path}'}
            
        analysis = {
            'module_path': module_path,
            'analysis_timestamp': time.time(),
            'file_stats': {},
            'code_complexity': {},
            'dependencies': {},
            'api_surface': {},
            'performance_hotspots': [],
            'research_gaps': [],
            'optimization_opportunities': []
        }
        
        # Analyze files in module
        if full_path.is_file() and full_path.suffix == '.py':
            files_to_analyze = [full_path]
        else:
            files_to_analyze = list(full_path.glob('*.py'))
            
        for file_path in files_to_analyze:
            file_analysis = self._analyze_python_file(file_path)
            relative_path = file_path.relative_to(self.python_root)
            analysis['file_stats'][str(relative_path)] = file_analysis
            
        # Generate research opportunities
        analysis['research_gaps'] = self._identify_research_gaps(analysis)
        analysis['optimization_opportunities'] = self._identify_optimizations(analysis)
        
        return analysis
        
    def _analyze_python_file(self, file_path: Path) -> Dict[str, Any]:
        """Deep analysis of individual Python file"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
                
            # Parse AST for detailed analysis
            tree = ast.parse(content)
            
            analysis = {
                'file_size': len(content),
                'lines_of_code': len(content.splitlines()),
                'classes': [],
                'functions': [],
                'imports': [],
                'complexity_score': 0,
                'memory_hotspots': [],
                'performance_patterns': [],
                'security_patterns': []
            }
            
            # AST analysis
            for node in ast.walk(tree):
                if isinstance(node, ast.ClassDef):
                    class_info = {
                        'name': node.name,
                        'line': node.lineno,
                        'methods': [n.name for n in node.body if isinstance(n, ast.FunctionDef)],
                        'docstring': ast.get_docstring(node),
                        'decorators': [d.id if isinstance(d, ast.Name) else str(d) for d in node.decorator_list]
                    }
                    analysis['classes'].append(class_info)
                    
                elif isinstance(node, ast.FunctionDef):
                    func_info = {
                        'name': node.name,
                        'line': node.lineno,
                        'args': len(node.args.args),
                        'docstring': ast.get_docstring(node),
                        'is_async': isinstance(node, ast.AsyncFunctionDef),
                        'decorators': [d.id if isinstance(d, ast.Name) else str(d) for d in node.decorator_list]
                    }
                    analysis['functions'].append(func_info)
                    
                elif isinstance(node, ast.Import):
                    for alias in node.names:
                        analysis['imports'].append(alias.name)
                        
                elif isinstance(node, ast.ImportFrom):
                    if node.module:
                        for alias in node.names:
                            analysis['imports'].append(f"{node.module}.{alias.name}")
                            
            # Calculate complexity score
            analysis['complexity_score'] = self._calculate_complexity(tree)
            
            # Identify performance patterns
            analysis['performance_patterns'] = self._identify_performance_patterns(content)
            
            # Security pattern analysis
            analysis['security_patterns'] = self._identify_security_patterns(content)
            
            return analysis
            
        except Exception as e:
            return {'error': str(e), 'file_path': str(file_path)}
            
    def _calculate_complexity(self, tree: ast.AST) -> float:
        """Calculate McCabe complexity score"""
        complexity = 1  # Base complexity
        
        for node in ast.walk(tree):
            if isinstance(node, (ast.If, ast.While, ast.For, ast.AsyncFor)):
                complexity += 1
            elif isinstance(node, ast.ExceptHandler):
                complexity += 1
            elif isinstance(node, (ast.And, ast.Or)):
                complexity += 1
                
        return complexity
        
    def _identify_performance_patterns(self, content: str) -> List[str]:
        """Identify performance-critical code patterns"""
        patterns = []
        
        # Memory-intensive patterns
        if '.append(' in content:
            patterns.append('list_append_operations')
        if 'np.array' in content:
            patterns.append('numpy_array_operations')
        if 'for ' in content and 'range(' in content:
            patterns.append('loop_operations')
        if 'time.sleep' in content:
            patterns.append('blocking_operations')
        if 'await ' in content:
            patterns.append('async_operations')
            
        # Optimization patterns
        if '__slots__' in content:
            patterns.append('memory_optimization')
        if 'lru_cache' in content:
            patterns.append('caching_optimization')
        if 'numba' in content or '@jit' in content:
            patterns.append('jit_optimization')
            
        return patterns
        
    def _identify_security_patterns(self, content: str) -> List[str]:
        """Identify potential security concerns"""
        patterns = []
        
        # Dangerous patterns
        if 'eval(' in content:
            patterns.append('eval_usage')
        if 'exec(' in content:
            patterns.append('exec_usage')
        if 'subprocess.' in content:
            patterns.append('subprocess_usage')
        if 'pickle.' in content:
            patterns.append('pickle_usage')
            
        # Good security practices
        if 'getenv(' in content:
            patterns.append('environment_variables')
        if 'try:' in content and 'except' in content:
            patterns.append('exception_handling')
            
        return patterns
        
    def _identify_research_gaps(self, analysis: Dict[str, Any]) -> List[str]:
        """Identify areas for AI research and enhancement"""
        gaps = []
        
        module_path = analysis['module_path']
        
        # Strategy-specific research gaps
        if 'strategies' in module_path:
            gaps.extend([
                'machine_learning_signal_enhancement',
                'adaptive_parameter_optimization',
                'market_regime_detection',
                'cross_asset_correlation_analysis',
                'advanced_risk_adjusted_returns'
            ])
            
        # Risk management research gaps
        if 'risk' in module_path:
            gaps.extend([
                'copula_based_risk_modeling',
                'tail_risk_management',
                'regime_aware_risk_budgeting',
                'dynamic_correlation_modeling',
                'stress_testing_methodologies'
            ])
            
        # Algorithm optimization gaps
        if 'algorithms' in module_path or 'optimized' in module_path:
            gaps.extend([
                'jit_compilation_opportunities',
                'simd_vectorization_potential',
                'gpu_acceleration_feasibility', 
                'lock_free_algorithms',
                'cache_optimization_techniques'
            ])
            
        # Data processing gaps
        if 'data_fabric' in module_path:
            gaps.extend([
                'real_time_anomaly_detection',
                'advanced_consensus_algorithms',
                'data_quality_ml_models',
                'stream_processing_optimization',
                'distributed_data_validation'
            ])
            
        return gaps
        
    def _identify_optimizations(self, analysis: Dict[str, Any]) -> List[Dict[str, str]]:
        """Identify specific optimization opportunities"""
        opportunities = []
        
        for file_path, file_stats in analysis['file_stats'].items():
            # Large file optimization
            if file_stats.get('file_size', 0) > 20000:  # >20KB
                opportunities.append({
                    'type': 'file_size_optimization',
                    'file': file_path,
                    'description': f'Large file ({file_stats["file_size"]} bytes) may benefit from modularization',
                    'priority': 'medium'
                })
                
            # High complexity optimization
            if file_stats.get('complexity_score', 0) > 20:
                opportunities.append({
                    'type': 'complexity_reduction',
                    'file': file_path, 
                    'description': f'High complexity score ({file_stats["complexity_score"]}) suggests refactoring needed',
                    'priority': 'high'
                })
                
            # Performance pattern optimization
            perf_patterns = file_stats.get('performance_patterns', [])
            if 'loop_operations' in perf_patterns and 'memory_optimization' not in perf_patterns:
                opportunities.append({
                    'type': 'memory_optimization',
                    'file': file_path,
                    'description': 'Loop operations without __slots__ optimization',
                    'priority': 'medium'
                })
                
        return opportunities
        
    def generate_agent_prompt(self, agent_type: str, analysis: Dict[str, Any]) -> str:
        """Generate specialized prompt for specific AI agent"""
        
        if agent_type.lower() == 'gemini':
            return self._generate_gemini_prompt(analysis)
        elif agent_type.lower() == 'gpt4':
            return self._generate_gpt4_prompt(analysis)
        elif agent_type.lower() == 'claude':
            return self._generate_claude_prompt(analysis)
        else:
            return self._generate_generic_prompt(analysis)
            
    def _generate_gemini_prompt(self, analysis: Dict[str, Any]) -> str:
        """Generate research-focused prompt for Gemini Pro"""
        prompt = f"""
# üî¨ GEMINI PRO - ADVANCED ALGORITHM RESEARCH REQUEST

## PROJECT CONTEXT
**Supreme System V5** - Ultra-constrained cryptocurrency trading bot
**Status:** Production-ready, 400+ KB codebase, 88.9% component success rate
**Target:** Advanced optimization and cutting-edge algorithm integration

## ANALYSIS RESULTS
**Modules Analyzed:** {len(analysis.get('module_analysis', {}))}
**Total Files:** {sum(len(m.get('file_stats', {})) for m in analysis.get('module_analysis', {}).values())}
**Research Gaps Identified:** {sum(len(m.get('research_gaps', [])) for m in analysis.get('module_analysis', {}).values())}

## PRIORITY RESEARCH AREAS
"""
        
        # Add research gaps by priority
        all_gaps = set()
        for module_analysis in analysis.get('module_analysis', {}).values():
            all_gaps.update(module_analysis.get('research_gaps', []))
            
        for i, gap in enumerate(sorted(all_gaps), 1):
            prompt += f"\n{i}. **{gap.replace('_', ' ').title()}**"
            
        prompt += f"""

## SPECIFIC RESEARCH REQUESTS

### 1. MATHEMATICAL OPTIMIZATION
**Current State:** O(1) indicators, 1-5ms latency, <450MB memory
**Research Goal:** Achieve <100Œºs latency, <300MB memory, >65% signal accuracy
**Focus Areas:** 
- Stochastic processes for price modeling
- Advanced optimization algorithms
- High-frequency trading mathematics
- Risk management innovations

### 2. ALGORITHM ENHANCEMENT
**Current State:** EMA/RSI/MACD traditional indicators
**Research Goal:** ML-enhanced signal generation with adaptive parameters
**Focus Areas:**
- Machine learning integration strategies
- Ensemble methods for signal validation
- Adaptive indicator optimization
- Real-time model updating

### 3. PERFORMANCE BREAKTHROUGH
**Current State:** Python-based with performance optimizations
**Research Goal:** Institutional-grade performance in constrained environment
**Focus Areas:**
- JIT compilation techniques
- Memory pooling and allocation
- Concurrent algorithm design
- Cache-optimized data structures

## DELIVERABLES REQUESTED
1. **Mathematical Formulations** - Detailed equations with parameters
2. **Algorithm Pseudocode** - Implementation-ready specifications
3. **Performance Analysis** - Expected improvements with benchmarks
4. **Integration Strategy** - Step-by-step implementation plan
5. **Risk Assessment** - Potential issues and mitigation strategies

## SUCCESS CRITERIA
- Quantifiable performance improvements (>20%)
- Maintain ultra-constrained resource requirements
- Production-ready implementation guidance
- Competitive advantage analysis

**Research Deadline:** Please prioritize top 3-5 opportunities for immediate impact.
"""
        
        return prompt
        
    def _generate_claude_prompt(self, analysis: Dict[str, Any]) -> str:
        """Generate implementation-focused prompt for Claude"""
        prompt = f"""
# üß† CLAUDE - SYSTEM IMPLEMENTATION & OPTIMIZATION REQUEST

## CURRENT SYSTEM STATUS
**Supreme System V5** - Production-ready trading bot
**Performance:** 88.9% component success, <450MB RAM, <85% CPU
**Codebase:** 400+ KB across 40+ files
**Status:** All critical issues resolved, ready for advanced optimization

## IMPLEMENTATION TASKS

### HIGH PRIORITY OPTIMIZATIONS
"""
        
        # Add optimization opportunities
        all_opportunities = []
        for module_analysis in analysis.get('module_analysis', {}).values():
            all_opportunities.extend(module_analysis.get('optimization_opportunities', []))
            
        for opp in all_opportunities[:10]:  # Top 10
            prompt += f"\n- **{opp['type'].replace('_', ' ').title()}** ({opp['priority']} priority)"
            prompt += f"\n  File: {opp['file']}"
            prompt += f"\n  Description: {opp['description']}\n"
            
        prompt += f"""

### IMPLEMENTATION REQUIREMENTS
- Maintain ultra-constrained resource limits
- Preserve production stability
- Include comprehensive testing
- Update documentation
- Validate performance improvements

### TESTING STRATEGY
- Unit tests for all changes
- Integration tests for system compatibility
- Performance benchmarks before/after
- Resource usage validation
- Stress testing under constraints

## EXPECTED DELIVERABLES
1. **Code Implementation** - Production-ready optimizations
2. **Test Cases** - Comprehensive validation suite
3. **Performance Metrics** - Before/after benchmarks
4. **Documentation Updates** - User guides and technical docs
5. **Migration Plan** - Safe deployment strategy

**Implementation Focus:** Maximize performance while maintaining stability and resource constraints.
"""
        
        return prompt
        
    def _generate_gpt4_prompt(self, analysis: Dict[str, Any]) -> str:
        """Generate review-focused prompt for GPT-4"""
        prompt = f"""
# üöÄ GPT-4 - COMPREHENSIVE CODE REVIEW & QUALITY ASSURANCE

## CODEBASE OVERVIEW
**Supreme System V5** - Cryptocurrency trading bot (production-ready)
**Scale:** 400+ KB code, 40+ Python files, 12 major modules
**Performance:** <450MB memory, <5ms latency, 88.9% success rate

## REVIEW OBJECTIVES

### 1. CODE QUALITY ASSESSMENT
**Focus Areas:**
- Code maintainability and readability
- Design patterns and architecture
- Error handling and edge cases
- API design and usability
- Type safety and validation

### 2. SECURITY REVIEW
**Security Patterns to Validate:**
- Input validation and sanitization
- Secret management and encryption
- Error information disclosure
- Dependency security
- Authentication and authorization

### 3. PERFORMANCE REVIEW
**Performance Criteria:**
- Memory allocation efficiency
- CPU optimization techniques
- I/O operation optimization
- Caching strategy effectiveness
- Concurrency and thread safety

### 4. TEST COVERAGE ANALYSIS
**Testing Requirements:**
- Unit test coverage >80%
- Integration test completeness
- Edge case coverage
- Performance regression tests
- Security test cases

## SPECIFIC REVIEW ITEMS
"""
        
        # Add specific files for review
        high_priority_files = [
            'strategies.py',
            'risk.py', 
            'core.py',
            'algorithms/scalping_futures_optimized.py',
            'data_fabric/advanced_aggregator.py'
        ]
        
        for file in high_priority_files:
            prompt += f"\n- **{file}** - Core component requiring thorough review"
            
        prompt += f"""

## DELIVERABLES REQUESTED
1. **Detailed Code Review** - Line-by-line analysis of critical components
2. **Security Assessment** - Vulnerability analysis and recommendations
3. **Performance Recommendations** - Optimization opportunities with code examples
4. **Test Case Suggestions** - Additional test scenarios for improved coverage
5. **Refactoring Plan** - Systematic code improvement strategy

## REVIEW CRITERIA
- **Maintainability:** Easy to understand and modify
- **Reliability:** Robust error handling and edge cases
- **Performance:** Efficient resource usage and execution
- **Security:** Secure coding practices and vulnerability prevention
- **Testability:** Comprehensive test coverage and quality

**Review Focus:** Ensure production-ready quality while identifying enhancement opportunities.
"""
        
        return prompt
        
    def _generate_generic_prompt(self, analysis: Dict[str, Any]) -> str:
        """Generate generic analysis prompt"""
        return f"""
# ü§ñ AI AGENT - SUPREME SYSTEM V5 ANALYSIS REQUEST

## PROJECT SUMMARY
Advanced cryptocurrency trading bot with ultra-constrained resource requirements.
400+ KB production codebase with comprehensive feature set.

## ANALYSIS RESULTS
{json.dumps(analysis, indent=2)}

## REQUEST
Please analyze this system and provide recommendations for improvement.
"""
        
    def run_full_system_analysis(self) -> Dict[str, Any]:
        """Analyze entire system comprehensively"""
        print("üîç Running full system analysis...")
        
        # Key modules to analyze
        key_modules = [
            'strategies.py',
            'core.py', 
            'risk.py',
            'algorithms/',
            'data_fabric/',
            'exchanges/',
            'optimized/',
            'backtest.py',
            'backtest_enhanced.py'
        ]
        
        for module in key_modules:
            print(f"   Analyzing {module}...")
            module_analysis = self.analyze_module(module)
            self.analysis_results['module_analysis'][module] = module_analysis
            
        # Generate project-wide metrics
        self._calculate_project_metrics()
        
        # Generate recommendations for each agent
        self._generate_agent_recommendations()
        
        return self.analysis_results
        
    def _calculate_project_metrics(self):
        """Calculate project-wide metrics"""
        total_files = 0
        total_lines = 0
        total_classes = 0
        total_functions = 0
        total_complexity = 0
        
        for module_analysis in self.analysis_results['module_analysis'].values():
            for file_stats in module_analysis.get('file_stats', {}).values():
                if isinstance(file_stats, dict) and 'lines_of_code' in file_stats:
                    total_files += 1
                    total_lines += file_stats.get('lines_of_code', 0)
                    total_classes += len(file_stats.get('classes', []))
                    total_functions += len(file_stats.get('functions', []))
                    total_complexity += file_stats.get('complexity_score', 0)
                    
        self.analysis_results['project_stats'] = {
            'total_files_analyzed': total_files,
            'total_lines_of_code': total_lines,
            'total_classes': total_classes,
            'total_functions': total_functions,
            'average_complexity': total_complexity / max(total_files, 1),
            'analysis_completion': f"{total_files} files"
        }
        
    def _generate_agent_recommendations(self):
        """Generate specific recommendations for each agent type"""
        self.analysis_results['agent_recommendations'] = {
            'gemini_research_priorities': [
                'Advanced mathematical optimization algorithms',
                'Machine learning integration strategies',
                'High-frequency trading techniques',
                'Modern portfolio theory applications',
                'Real-time risk management models'
            ],
            'claude_implementation_tasks': [
                'Performance optimization of critical paths',
                'Memory usage reduction techniques',
                'Latency optimization strategies', 
                'Integration testing improvements',
                'Documentation enhancement'
            ],
            'gpt4_review_focus': [
                'Code quality and maintainability review',
                'Security vulnerability assessment',
                'Test coverage analysis and improvement',
                'API design and usability review',
                'Refactoring recommendations'
            ]
        }
        
    def save_analysis_results(self, filename: str = None) -> Path:
        """Save comprehensive analysis results"""
        if filename is None:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f"deep_analysis_{timestamp}.json"
            
        output_path = self.output_dir / filename
        
        with open(output_path, 'w') as f:
            json.dump(self.analysis_results, f, indent=2, default=str)
            
        print(f"üíæ Analysis saved to: {output_path}")
        return output_path
        
    def generate_agent_prompts(self, agents: List[str] = None) -> Dict[str, Path]:
        """Generate prompts for specified agents"""
        if agents is None:
            agents = ['gemini', 'claude', 'gpt4']
            
        prompt_files = {}
        
        for agent in agents:
            prompt_content = self.generate_agent_prompt(agent, self.analysis_results)
            
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            prompt_filename = f"{agent.upper()}_RESEARCH_PROMPT_{timestamp}.md"
            prompt_path = self.output_dir / prompt_filename
            
            with open(prompt_path, 'w') as f:
                f.write(prompt_content)
                
            prompt_files[agent] = prompt_path
            print(f"üìù {agent.upper()} prompt generated: {prompt_path}")
            
        return prompt_files

async def main():
    """Main analysis execution"""
    parser = argparse.ArgumentParser(description='Agentic Deep Review System')
    parser.add_argument('--module', type=str, help='Specific module to analyze')
    parser.add_argument('--agent', type=str, choices=['gemini', 'claude', 'gpt4'], 
                       help='Generate prompt for specific agent')
    parser.add_argument('--full-system', action='store_true', help='Analyze entire system')
    parser.add_argument('--output', type=str, default='run_artifacts/agents', help='Output directory')
    
    args = parser.parse_args()
    
    print(f"Configuration:")
    print(f"  Module: {args.module or 'Full system'}")
    print(f"  Agent: {args.agent or 'All agents'}")
    print(f"  Output: {args.output}")
    print()
    
    # Initialize analyzer
    analyzer = CodeIntelligenceAnalyzer(args.output)
    
    try:
        if args.module:
            # Single module analysis
            print(f"üîç Analyzing single module: {args.module}")
            module_analysis = analyzer.analyze_module(args.module)
            analyzer.analysis_results['module_analysis'][args.module] = module_analysis
        else:
            # Full system analysis
            print(f"üîç Running comprehensive system analysis")
            analyzer.run_full_system_analysis()
            
        # Save analysis results
        analysis_file = analyzer.save_analysis_results()
        
        # Generate agent prompts
        if args.agent:
            prompt_files = analyzer.generate_agent_prompts([args.agent])
        else:
            prompt_files = analyzer.generate_agent_prompts()
            
        # Print summary
        print(f"\nüéØ Analysis Complete!")
        print(f"   Analysis file: {analysis_file}")
        print(f"   Agent prompts: {len(prompt_files)}")
        
        for agent, prompt_file in prompt_files.items():
            print(f"   - {agent.upper()}: {prompt_file}")
            
        # Print next steps
        print(f"\nüöÄ Next Steps:")
        print(f"   1. Copy appropriate prompt file to your AI agent")
        print(f"   2. Review analysis results in {analysis_file}")
        print(f"   3. Implement recommended optimizations")
        print(f"   4. Run validation: python scripts/fix_all_issues.py")
        
        return 0
        
    except Exception as e:
        print(f"\n‚ùå Analysis failed: {e}")
        return 1

if __name__ == "__main__":
    import asyncio
    exit_code = asyncio.run(main())
    sys.exit(exit_code)