"""
ðŸ“ˆ Supreme System V5 - Prometheus Metrics Exporter
Core metrics collection and export for monitoring

Features:
- 8 Tier-1 core metrics as specified
- Real-time metrics collection
- Prometheus format export
- Performance tracking
- Alert-ready thresholds
- Grafana dashboard compatibility
"""

import time
import asyncio
from datetime import datetime, timedelta
from typing import Dict, Any, Optional, List
from dataclasses import dataclass, field
from enum import Enum
import logging
from collections import defaultdict, deque

try:
    from prometheus_client import (
        CollectorRegistry, Gauge, Counter, Histogram, Summary,
        generate_latest, start_http_server, CONTENT_TYPE_LATEST
    )
    PROMETHEUS_AVAILABLE = True
except ImportError:
    PROMETHEUS_AVAILABLE = False
    # Mock classes for graceful degradation
    class Gauge:
        def __init__(self, *args, **kwargs): pass
        def set(self, value): pass
        def inc(self, amount=1): pass
    
    class Counter:
        def __init__(self, *args, **kwargs): pass
        def inc(self, amount=1): pass
    
    class Histogram:
        def __init__(self, *args, **kwargs): pass
        def observe(self, value): pass
    
    def start_http_server(port): pass
    def generate_latest(registry=None): return b"# Prometheus not available\n"

logger = logging.getLogger("supreme_metrics")

class MetricType(Enum):
    GAUGE = "gauge"
    COUNTER = "counter"
    HISTOGRAM = "histogram"
    SUMMARY = "summary"

@dataclass
class MetricDefinition:
    name: str
    description: str
    metric_type: MetricType
    labels: List[str] = field(default_factory=list)
    buckets: Optional[List[float]] = None

class PrometheusExporter:
    """Prometheus metrics exporter for Supreme System V5"""
    
    def __init__(self, port: int = 9090):
        self.port = port
        self.registry = CollectorRegistry() if PROMETHEUS_AVAILABLE else None
        self.metrics: Dict[str, Any] = {}
        self.is_running = False
        self.server_started = False
        self.last_update = time.time()
        
        # Initialize Tier-1 core metrics
        self._initialize_core_metrics()
        
        logger.info(f"ðŸ“ˆ Prometheus exporter initialized on port {port}")
        if not PROMETHEUS_AVAILABLE:
            logger.warning("âš ï¸ Prometheus client not available - metrics will be mocked")
    
    def _initialize_core_metrics(self):
        """Initialize the 8 Tier-1 core metrics"""
        
        # Define core metrics according to requirements
        core_metric_definitions = {
            "api_latency_ms": MetricDefinition(
                name="supreme_api_latency_milliseconds",
                description="API endpoint response latency in milliseconds",
                metric_type=MetricType.HISTOGRAM,
                labels=["endpoint", "method"],
                buckets=[1, 5, 10, 25, 50, 100, 250, 500, 1000]
            ),
            "websocket_clients": MetricDefinition(
                name="supreme_websocket_clients_total",
                description="Number of active WebSocket connections",
                metric_type=MetricType.GAUGE
            ),
            "trading_loop_ms": MetricDefinition(
                name="supreme_trading_loop_milliseconds",
                description="Trading loop execution time in milliseconds",
                metric_type=MetricType.HISTOGRAM,
                buckets=[1, 5, 10, 25, 50, 100, 250, 500]
            ),
            "orders_executed": MetricDefinition(
                name="supreme_orders_executed_total",
                description="Total number of orders executed",
                metric_type=MetricType.COUNTER,
                labels=["symbol", "side", "status"]
            ),
            "pnl_daily": MetricDefinition(
                name="supreme_pnl_daily_usd",
                description="Daily profit and loss in USD",
                metric_type=MetricType.GAUGE,
                labels=["date"]
            ),
            "exchange_connectivity": MetricDefinition(
                name="supreme_exchange_connectivity",
                description="Exchange connection status (1=connected, 0=disconnected)",
                metric_type=MetricType.GAUGE,
                labels=["exchange"]
            ),
            "gross_exposure_usd": MetricDefinition(
                name="supreme_gross_exposure_usd",
                description="Total gross exposure in USD",
                metric_type=MetricType.GAUGE
            ),
            "max_drawdown_pct": MetricDefinition(
                name="supreme_max_drawdown_percent",
                description="Maximum drawdown percentage",
                metric_type=MetricType.GAUGE,
                labels=["period"]
            )
        }
        
        # Create Prometheus metrics
        for key, definition in core_metric_definitions.items():
            try:
                if definition.metric_type == MetricType.GAUGE:
                    metric = Gauge(
                        definition.name,
                        definition.description,
                        labelnames=definition.labels,
                        registry=self.registry
                    )
                elif definition.metric_type == MetricType.COUNTER:
                    metric = Counter(
                        definition.name,
                        definition.description,
                        labelnames=definition.labels,
                        registry=self.registry
                    )
                elif definition.metric_type == MetricType.HISTOGRAM:
                    metric = Histogram(
                        definition.name,
                        definition.description,
                        labelnames=definition.labels,
                        buckets=definition.buckets,
                        registry=self.registry
                    )
                
                self.metrics[key] = metric
                logger.debug(f"Initialized metric: {definition.name}")
                
            except Exception as e:
                logger.error(f"Failed to initialize metric {key}: {e}")
                # Create mock metric for graceful degradation
                self.metrics[key] = type('MockMetric', (), {
                    'set': lambda self, *args, **kwargs: None,
                    'inc': lambda self, *args, **kwargs: None,
                    'observe': lambda self, *args, **kwargs: None,
                    'labels': lambda *args, **kwargs: self
                })()
    
    async def start_server(self):
        """Start Prometheus HTTP server"""
        if self.server_started or not PROMETHEUS_AVAILABLE:
            return
        
        try:
            start_http_server(self.port, registry=self.registry)
            self.server_started = True
            self.is_running = True
            logger.info(f"âœ… Prometheus server started on port {self.port}")
            logger.info(f"   Metrics endpoint: http://localhost:{self.port}/metrics")
        except Exception as e:
            logger.error(f"âŒ Failed to start Prometheus server: {e}")
    
    def stop_server(self):
        """Stop metrics collection"""
        self.is_running = False
        logger.info("ðŸ›‘ Prometheus metrics collection stopped")
    
    # Tier-1 Core Metrics Update Methods
    
    def update_api_latency(self, endpoint: str, method: str, latency_ms: float):
        """Update API latency metric"""
        try:
            self.metrics["api_latency_ms"].labels(endpoint=endpoint, method=method).observe(latency_ms)
        except Exception as e:
            logger.debug(f"API latency update failed: {e}")
    
    def update_websocket_clients(self, count: int):
        """Update WebSocket client count"""
        try:
            self.metrics["websocket_clients"].set(count)
        except Exception as e:
            logger.debug(f"WebSocket clients update failed: {e}")
    
    def update_trading_loop_time(self, duration_ms: float):
        """Update trading loop execution time"""
        try:
            self.metrics["trading_loop_ms"].observe(duration_ms)
        except Exception as e:
            logger.debug(f"Trading loop time update failed: {e}")
    
    def increment_orders_executed(self, symbol: str, side: str, status: str, count: int = 1):
        """Increment orders executed counter"""
        try:
            self.metrics["orders_executed"].labels(symbol=symbol, side=side, status=status).inc(count)
        except Exception as e:
            logger.debug(f"Orders executed update failed: {e}")
    
    def update_pnl_daily(self, pnl_usd: float, date: str = None):
        """Update daily PnL"""
        if date is None:
            date = datetime.utcnow().strftime("%Y-%m-%d")
        try:
            self.metrics["pnl_daily"].labels(date=date).set(pnl_usd)
        except Exception as e:
            logger.debug(f"Daily PnL update failed: {e}")
    
    def update_exchange_connectivity(self, exchange: str, connected: bool):
        """Update exchange connectivity status"""
        try:
            self.metrics["exchange_connectivity"].labels(exchange=exchange).set(1 if connected else 0)
        except Exception as e:
            logger.debug(f"Exchange connectivity update failed: {e}")
    
    def update_gross_exposure(self, exposure_usd: float):
        """Update gross exposure"""
        try:
            self.metrics["gross_exposure_usd"].set(exposure_usd)
        except Exception as e:
            logger.debug(f"Gross exposure update failed: {e}")
    
    def update_max_drawdown(self, drawdown_pct: float, period: str = "daily"):
        """Update maximum drawdown percentage"""
        try:
            self.metrics["max_drawdown_pct"].labels(period=period).set(drawdown_pct)
        except Exception as e:
            logger.debug(f"Max drawdown update failed: {e}")
    
    def get_metrics_text(self) -> str:
        """Get metrics in Prometheus text format"""
        if not PROMETHEUS_AVAILABLE or not self.registry:
            return "# Prometheus not available\n"
        
        try:
            return generate_latest(self.registry).decode('utf-8')
        except Exception as e:
            logger.error(f"Failed to generate metrics: {e}")
            return f"# Error generating metrics: {e}\n"
    
    def get_metrics_summary(self) -> Dict[str, Any]:
        """Get summary of current metrics"""
        return {
            "prometheus_available": PROMETHEUS_AVAILABLE,
            "server_running": self.is_running,
            "server_port": self.port,
            "metrics_count": len(self.metrics),
            "core_metrics": list(self.metrics.keys()),
            "last_update": datetime.fromtimestamp(self.last_update).isoformat(),
            "uptime_seconds": time.time() - self.last_update if self.is_running else 0
        }

class MetricsCollector:
    """Automated metrics collection from system components"""
    
    def __init__(self, exporter: PrometheusExporter):
        self.exporter = exporter
        self.collection_interval = 15.0  # 15 seconds
        self.is_collecting = False
        self.collection_task: Optional[asyncio.Task] = None
        
        # Metrics cache for performance
        self.metrics_cache: Dict[str, deque] = defaultdict(lambda: deque(maxlen=100))
        
        logger.info("ðŸ“ˆ Metrics collector initialized")
    
    async def start_collection(self):
        """Start automated metrics collection"""
        if self.is_collecting:
            return
        
        self.is_collecting = True
        self.collection_task = asyncio.create_task(self._collection_loop())
        logger.info(f"âœ… Metrics collection started (interval: {self.collection_interval}s)")
    
    def stop_collection(self):
        """Stop automated metrics collection"""
        self.is_collecting = False
        if self.collection_task:
            self.collection_task.cancel()
        logger.info("ðŸ›‘ Metrics collection stopped")
    
    async def _collection_loop(self):
        """Main collection loop"""
        while self.is_collecting:
            try:
                await self.collect_system_metrics()
                await asyncio.sleep(self.collection_interval)
            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"Metrics collection error: {e}")
                await asyncio.sleep(self.collection_interval)
    
    async def collect_system_metrics(self):
        """Collect metrics from system components"""
        try:
            # This would integrate with actual system components
            # For now, simulate metrics collection
            
            # WebSocket clients (from global handler)
            try:
                from ..api.websocket import websocket_handler
                ws_stats = websocket_handler.get_connection_stats()
                self.exporter.update_websocket_clients(ws_stats["active_connections"])
            except:
                pass
            
            # Trading engine metrics (if available)
            try:
                from ..trading.engine import trading_engine
                if trading_engine and hasattr(trading_engine, 'performance_metrics'):
                    metrics = trading_engine.performance_metrics
                    
                    # Update orders executed
                    if 'orders_executed' in metrics:
                        # This would need proper symbol/side tracking
                        pass
                    
                    # Update daily PnL
                    if hasattr(trading_engine, 'portfolio') and trading_engine.portfolio:
                        pnl = trading_engine.portfolio.daily_pnl
                        self.exporter.update_pnl_daily(pnl)
                        
                        # Calculate gross exposure
                        total_value = trading_engine.portfolio.get_portfolio_summary().get('total_value_usd', 0)
                        self.exporter.update_gross_exposure(abs(total_value))
            except:
                pass
            
            # Exchange connectivity (simulate)
            self.exporter.update_exchange_connectivity("binance", True)
            
            # Default drawdown (would be calculated from actual trading history)
            self.exporter.update_max_drawdown(2.1, "daily")
            
        except Exception as e:
            logger.error(f"System metrics collection failed: {e}")
    
    def collect_api_metrics(self, endpoint: str, method: str, duration_ms: float):
        """Collect API performance metrics"""
        self.exporter.update_api_latency(endpoint, method, duration_ms)
        
        # Cache for trend analysis
        self.metrics_cache[f"api_{endpoint}_{method}"].append({
            "timestamp": time.time(),
            "duration_ms": duration_ms
        })
    
    def collect_trading_metrics(self, symbol: str, side: str, status: str, duration_ms: float = None):
        """Collect trading-specific metrics"""
        self.exporter.increment_orders_executed(symbol, side, status)
        
        if duration_ms is not None:
            self.exporter.update_trading_loop_time(duration_ms)
    
    def get_cached_metrics(self, metric_name: str, minutes: int = 5) -> List[Dict]:
        """Get cached metrics for trend analysis"""
        cutoff_time = time.time() - (minutes * 60)
        cached = self.metrics_cache.get(metric_name, [])
        return [m for m in cached if m["timestamp"] > cutoff_time]

# Global instances
prometheus_exporter: Optional[PrometheusExporter] = None
metrics_collector: Optional[MetricsCollector] = None

def start_metrics_server(port: int = 9090) -> PrometheusExporter:
    """Start Prometheus metrics server"""
    global prometheus_exporter, metrics_collector
    
    if prometheus_exporter is None:
        prometheus_exporter = PrometheusExporter(port)
        metrics_collector = MetricsCollector(prometheus_exporter)
    
    return prometheus_exporter

async def initialize_monitoring(port: int = 9090):
    """Initialize complete monitoring system"""
    global prometheus_exporter, metrics_collector
    
    # Start Prometheus server
    prometheus_exporter = start_metrics_server(port)
    await prometheus_exporter.start_server()
    
    # Start metrics collection
    if metrics_collector:
        await metrics_collector.start_collection()
    
    logger.info("ðŸš€ Supreme System V5 monitoring fully initialized")

def get_metrics_summary() -> Dict[str, Any]:
    """Get comprehensive metrics summary"""
    if not prometheus_exporter:
        return {"status": "not_initialized"}
    
    summary = prometheus_exporter.get_metrics_summary()
    
    if metrics_collector:
        summary["collector"] = {
            "collecting": metrics_collector.is_collecting,
            "interval_seconds": metrics_collector.collection_interval,
            "cached_metrics": len(metrics_collector.metrics_cache)
        }
    
    return summary

# Convenience function for API middleware
def track_api_request(endpoint: str, method: str, duration_ms: float):
    """Track API request metrics"""
    if metrics_collector:
        metrics_collector.collect_api_metrics(endpoint, method, duration_ms)

# Convenience function for trading metrics
def track_trading_activity(symbol: str, side: str, status: str, duration_ms: float = None):
    """Track trading activity metrics"""
    if metrics_collector:
        metrics_collector.collect_trading_metrics(symbol, side, status, duration_ms)

if __name__ == "__main__":
    # Demo monitoring setup
    import asyncio
    
    async def demo():
        print("ðŸ“ˆ Supreme System V5 Monitoring Demo")
        print("=" * 40)
        
        # Initialize monitoring
        await initialize_monitoring(9091)  # Use different port for demo
        
        # Simulate some metrics
        if prometheus_exporter:
            prometheus_exporter.update_websocket_clients(5)
            prometheus_exporter.update_api_latency("/api/v1/status", "GET", 15.2)
            prometheus_exporter.update_pnl_daily(125.50)
            prometheus_exporter.update_exchange_connectivity("binance", True)
        
        # Show summary
        summary = get_metrics_summary()
        print(f"ðŸ“‰ Metrics Summary:")
        print(f"   Prometheus available: {summary.get('prometheus_available')}")
        print(f"   Server running: {summary.get('server_running')}")
        print(f"   Core metrics: {len(summary.get('core_metrics', []))}")
        
        # Wait a bit then stop
        await asyncio.sleep(2)
        
        if prometheus_exporter:
            prometheus_exporter.stop_server()
        if metrics_collector:
            metrics_collector.stop_collection()
        
        print("ðŸš€ Monitoring demo completed")
    
    asyncio.run(demo())